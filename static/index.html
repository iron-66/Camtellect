<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Camtellect ‚Äì AIfyer</title>
  <style>
    html, body {
      margin: 0; padding: 0; height: 100%;
      font-family: 'Segoe UI', sans-serif;
      background: none; color: #fff;
      display: flex; align-items: center; justify-content: center; text-align: center;
    }
    body::before {
      content: "";
      position: fixed; inset: 0; z-index: -1;
      background: linear-gradient(135deg, #000 0%, #003366 35%, #5e3b85 70%, #e0b87b 100%);
    }
    .container {
      max-width: 720px; width: 100%; padding: 1rem; box-sizing: border-box;
    }
    h2 {
      font-size: clamp(1.5rem, 4vw, 3rem);
      margin-bottom: 1.5rem;
    }
    video {
      width: 100%; max-width: 400px;
      border-radius: 12px;
      box-shadow: 0 0 10px rgba(255,255,255,0.2);
      margin-bottom: 1rem;
    }
    .buttons {
      display: flex;
      flex-wrap: wrap;
      justify-content: center;
      align-items: center;
      gap: 0.5rem;
      margin-bottom: 1rem;
    }
    .buttons button {
      display: inline-flex;
      align-items: center;
      justify-content: center;
    }
    button, select {
      height: 50px;
      font-size: 1rem;
      padding: 0 1rem;
      border-radius: 8px;
      border: none;
      background: rgba(255,255,255,0.1);
      color: #fff;
      cursor: pointer;
      transition: background .3s;
    }
    button:hover:not(:disabled),
    select:hover {
      background: rgba(255,255,255,0.2);
    }
    select {
      background-color: rgba(255, 255, 255, 0.1);
      color: #ffffff;
      border: none;
      border-radius: 8px;
      padding: 0 1rem;
      font-size: 1rem;
    }
    select option {
      background-color: #1a1a1a;
      color: #ffffff;
    }
    button:disabled {
      opacity: .5;
      cursor: not-allowed;
    }
    #status {
      margin-top: 1rem;
      font-size: 1.1rem;
    }
    canvas { display: none; }
  </style>
</head>
<body>
  <div class="container">
    <h2>–î–ª—è —Ä–∞–±–æ—Ç—ã –Ω–µ–æ–±—Ö–æ–¥–∏–º –¥–æ—Å—Ç—É–ø –∫ –∫–∞–º–µ—Ä–µ –∏ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É</h2>
    <video id="camera" autoplay playsinline muted></video>
    <canvas id="snapshot"></canvas>

    <div class="buttons">
      <select id="cameraSelect" style="display:none"></select>
      <button id="recordButton" disabled>üé§ –ó–∞–ø–∏—Å–∞—Ç—å</button>
      <button id="playButton" style="display:none">‚ñ∂ –í–æ—Å–ø—Ä–æ–∏–∑–≤–µ—Å—Ç–∏</button>
    </div>

    <p id="status">–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è‚Ä¶</p>
  </div>

  <script>
    const video = document.getElementById('camera');
    const canvas = document.getElementById('snapshot');
    const cameraSelect = document.getElementById('cameraSelect');
    const recordBtn = document.getElementById('recordButton');
    const playBtn = document.getElementById('playButton');
    const statusEl = document.getElementById('status');

    let stream;
    let recorder;
    let isRecording = false;
    let audioCtx;
    let replyText = '';
    let currentVideoDeviceId = null;

    async function getDevices() {
      const devices = await navigator.mediaDevices.enumerateDevices();
      return devices.filter(d => d.kind === 'videoinput');
    }

    async function startStream(deviceId = null) {
      if (stream) stream.getTracks().forEach(t => t.stop());
      const constraints = { video: deviceId ? { deviceId: { exact: deviceId } } : true, audio: true };
      try {
        stream = await navigator.mediaDevices.getUserMedia(constraints);
        video.srcObject = stream;
        await video.play();
        currentVideoDeviceId = stream.getVideoTracks()[0].getSettings().deviceId;
        recordBtn.disabled = false;
        statusEl.textContent = '–ö–∞–º–µ—Ä–∞ –∞–∫—Ç–∏–≤–Ω–∞';
      } catch (err) {
        console.error('–û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ –∫–∞–º–µ—Ä–µ/–º–∏–∫—Ä–æ—Ñ–æ–Ω—É:', err);
        statusEl.textContent = '–û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ –∫–∞–º–µ—Ä–µ/–º–∏–∫—Ä–æ—Ñ–æ–Ω—É';
      }
    }

    async function init() {
      await startStream();
      const cameras = await getDevices();
      if (cameras.length > 1) {
        cameraSelect.innerHTML = '';
        cameras.forEach(cam => {
          const opt = document.createElement('option');
          opt.value = cam.deviceId;
          opt.textContent = cam.label || `–ö–∞–º–µ—Ä–∞ ${cameraSelect.length + 1}`;
          cameraSelect.appendChild(opt);
        });
        cameraSelect.value = currentVideoDeviceId;
        cameraSelect.style.display = 'inline-block';
        cameraSelect.addEventListener('change', () => {
          startStream(cameraSelect.value);
        });
      }
    }

    function unlockAudio() {
      if (audioCtx) return;
      audioCtx = new (window.AudioContext || window.webkitAudioContext)();
      const buf = audioCtx.createBuffer(1,1,22050);
      const src = audioCtx.createBufferSource();
      src.buffer = buf;
      src.connect(audioCtx.destination);
      src.start();
    }

    async function stopAndProcess() {
      statusEl.textContent = '–û–±—Ä–∞–±–æ—Ç–∫–∞‚Ä¶';
      const audioBlob = new Blob(recorder._chunks, { type: recorder.mimeType });
      canvas.width  = video.videoWidth;
      canvas.height = video.videoHeight;
      canvas.getContext('2d').drawImage(video, 0, 0);
      const imageBlob = await new Promise(r => canvas.toBlob(r, 'image/jpeg'));
      const fd = new FormData();
      const ext = recorder.mimeType.includes('mp4') ? 'mp4' : 'webm';
      fd.append('audio', audioBlob, `speech.${ext}`);
      fd.append('image', imageBlob, 'photo.jpg');

      try {
        const resp = await fetch('/process', { method: 'POST', body: fd });
        const data = await resp.json();
        statusEl.textContent = '–û—Ç–≤–µ—Ç: ' + data.reply;
        replyText = data.reply;
        playBtn.style.display = 'inline-block';

        const isIOS = /iP(hone|od|ad)/.test(navigator.userAgent) && !window.MSStream;
        if (!isIOS) {
          const utter = new SpeechSynthesisUtterance(replyText);
          utter.lang = 'ru-RU';
          speechSynthesis.speak(utter);
        }
      } catch (e) {
        console.error(e);
        statusEl.textContent = '–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ';
      }
    }

    function playReply() {
      const utter = new SpeechSynthesisUtterance(replyText);
      utter.lang = 'ru-RU';
      speechSynthesis.speak(utter);
    }

    recordBtn.addEventListener('click', () => { unlockAudio(); handleRecording(); });
    recordBtn.addEventListener('touchstart', e => { e.preventDefault(); unlockAudio(); handleRecording(); }, { passive: false });
    playBtn.addEventListener('click', playReply);
    playBtn.addEventListener('touchend', e => { e.preventDefault(); playReply(); }, { passive: false });

    function handleRecording() {
      if (!isRecording) {
        const options = {};
        if (MediaRecorder.isTypeSupported('audio/mp4')) {
          options.mimeType = 'audio/mp4';
        } else if (MediaRecorder.isTypeSupported('audio/webm;codecs=opus')) {
          options.mimeType = 'audio/webm;codecs=opus';
        }
        try {
          recorder = new MediaRecorder(new MediaStream(stream.getAudioTracks()), options);
        } catch (err) {
          console.error('MediaRecorder error:', err);
          statusEl.textContent = '–û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏: —Ñ–æ—Ä–º–∞—Ç –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è';
          return;
        }
        recorder._chunks = [];
        recorder.ondataavailable = e => { if (e.data.size) recorder._chunks.push(e.data); };
        recorder.onstop = stopAndProcess;
        recorder.onerror = e => { console.error('Recorder error:', e); statusEl.textContent = '–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏'; };
        recorder.start();
        isRecording = true;
        recordBtn.textContent = '‚ñ† –°—Ç–æ–ø';
        statusEl.textContent  = '–ó–∞–ø–∏—Å—å‚Ä¶';
      } else {
        recorder.stop();
        isRecording = false;
        recordBtn.textContent = 'üé§ –ó–∞–ø–∏—Å–∞—Ç—å';
      }
    }

    window.addEventListener('DOMContentLoaded', init);
  </script>
</body>
</html>
