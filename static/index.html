<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Camtellect ‚Äì AIfyer</title>
  <style>
    html, body {
      margin: 0; padding: 0; height: 100%;
      font-family: 'Segoe UI', sans-serif;
      background: none; color: #fff;
      display: flex; align-items: center; justify-content: center; text-align: center;
    }
    body::before {
      content: "";
      position: fixed; inset: 0; z-index: -1;
      background: linear-gradient(135deg,#000 0%,#003366 35%,#5e3b85 70%,#e0b87b 100%);
    }
    .container { max-width: 720px; width: 100%; padding: 1rem; box-sizing: border-box; }
    h2 { font-size: clamp(1.5rem,4vw,3rem); margin-bottom:1.5rem; }
    video {
      width:100%; max-width:400px; border-radius:12px;
      box-shadow:0 0 10px rgba(255,255,255,0.2); margin-bottom:1rem;
    }
    button {
      font-size:1.2rem; padding:0.8rem 1.5rem; border:none; border-radius:8px;
      background:rgba(255,255,255,0.1); color:#fff; cursor:pointer; transition:background .3s;
      margin: 0 .5rem .5rem 0; user-select: none; touch-action: manipulation;
    }
    button:disabled { opacity:.4; cursor:not-allowed; }
    button:hover:not(:disabled) { background:rgba(255,255,255,0.2); }
    .icon { margin-right:0.5rem; font-size:1.3em; vertical-align:middle; }
    #status { margin-top:1rem; font-size:1.1rem; }
    canvas { display:none; }
  </style>
</head>
<body>
  <div class="container">
    <h2>–î–ª—è —Ä–∞–±–æ—Ç—ã –Ω—É–∂–µ–Ω –¥–æ—Å—Ç—É–ø –∫ –∫–∞–º–µ—Ä–µ –∏ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É</h2>
    <video id="camera" autoplay playsinline muted></video>
    <canvas id="snapshot"></canvas>
    <br>
    <button id="switchCam" disabled>‚ü≥ –ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å –∫–∞–º–µ—Ä—É</button>
    <button id="recordButton" disabled><span class="icon">üé§</span>–ó–∞–ø–∏—Å–∞—Ç—å</button>
    <p id="status">–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è‚Ä¶</p>
  </div>

  <script>
    const switchBtn = document.getElementById('switchCam');
    const recordBtn = document.getElementById('recordButton');
    const statusEl  = document.getElementById('status');
    const video     = document.getElementById('camera');
    const canvas    = document.getElementById('snapshot');

    let stream;
    let currentFacing = 'user';
    let recorder = null;
    let isRecording = false;

    async function startStream() {
      if (stream) stream.getTracks().forEach(t => t.stop());
      try {
        stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: { exact: currentFacing } }, audio: true
        });
      } catch {
        stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: currentFacing }, audio: true
        });
      }
      video.srcObject = stream;
      await new Promise(res => {
        if (video.readyState >= 1) res(); else video.onloadedmetadata = () => res();
      });
      statusEl.textContent = '–ö–∞–º–µ—Ä–∞: ' + (currentFacing === 'user' ? '—Ñ—Ä–æ–Ω—Ç–∞–ª—å–Ω–∞—è' : '—Ç—ã–ª–æ–≤–∞—è');
      switchBtn.disabled = false;
      recordBtn.disabled = false;
    }

    switchBtn.addEventListener('click', async () => {
      currentFacing = currentFacing === 'user' ? 'environment' : 'user';
      statusEl.textContent = '–ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º‚Ä¶'; switchBtn.disabled = true; recordBtn.disabled = true;
      await startStream();
    });

    function handleStop() {
      statusEl.textContent = '–û–±—Ä–∞–±–æ—Ç–∫–∞‚Ä¶';
      const audioBlob = new Blob(recorder._chunks, { type: recorder.mimeType });
      canvas.width = video.videoWidth; canvas.height = video.videoHeight;
      canvas.getContext('2d').drawImage(video, 0, 0);
      canvas.toBlob(async blob => {
        const fd = new FormData();
        fd.append('audio', audioBlob, 'speech.webm');
        fd.append('image', blob, 'photo.jpg');
        try {
          const resp = await fetch('/process', { method: 'POST', body: fd });
          const data = await resp.json();
          statusEl.textContent = '–û—Ç–≤–µ—Ç: ' + data.reply;
          const u = new SpeechSynthesisUtterance(data.reply);
          u.lang = 'ru-RU'; speechSynthesis.speak(u);
        } catch (e) {
          console.error(e); statusEl.textContent = '–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –¥–∞–Ω–Ω—ã—Ö';
        }
      }, 'image/jpeg');
    }

    recordBtn.addEventListener('click', () => {
      if (!isRecording) {
        // start
        recorder = new MediaRecorder(new MediaStream(stream.getAudioTracks()), { mimeType: 'audio/webm;codecs=opus' });
        recorder._chunks = [];
        recorder.mimeType = recorder.mimeType;
        recorder.ondataavailable = e => { if (e.data.size) recorder._chunks.push(e.data); };
        recorder.onstop = handleStop;
        recorder.start();
        recordBtn.textContent = '‚ñ† –°—Ç–æ–ø';
        isRecording = true;
        statusEl.textContent = '–ó–∞–ø–∏—Å—å‚Ä¶';
      } else {
        // stop
        recorder.stop();
        recordBtn.innerHTML = '<span class="icon">üé§</span>–ó–∞–ø–∏—Å–∞—Ç—å';
        isRecording = false;
      }
    });

    window.addEventListener('DOMContentLoaded', startStream);
  </script>
</body>
</html>