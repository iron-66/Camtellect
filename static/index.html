<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Camtellect ‚Äì AIfyer</title>
  <style>
    html, body {
      margin: 0; padding: 0; height: 100%;
      font-family: 'Segoe UI', sans-serif;
      background: none; color: #fff;
      display: flex; align-items: center; justify-content: center; text-align: center;
    }
    body::before {
      content: "";
      position: fixed; inset: 0; z-index: -1;
      background: linear-gradient(135deg, #000 0%, #003366 35%, #5e3b85 70%, #e0b87b 100%);
    }
    .container {
      max-width: 720px; width: 100%; padding: 1rem; box-sizing: border-box;
    }
    h2 {
      font-size: clamp(1.5rem, 4vw, 3rem);
      margin-bottom: 1.5rem;
    }
    video {
      width: 100%; max-width: 400px;
      border-radius: 12px;
      box-shadow: 0 0 10px rgba(255,255,255,0.2);
      margin-bottom: 1rem;
    }
    .buttons {
      display: flex;
      flex-wrap: wrap;
      justify-content: center;
      align-items: center;
      gap: 0.5rem;
      margin-bottom: 1rem;
    }
    button {
      display: inline-flex;
      align-items: center;
      justify-content: center;
      height: 60px;
      box-sizing: border-box;
      font-size: 1.2rem;
      padding: 0 1.5rem;
      border: none;
      border-radius: 8px;
      background: rgba(255,255,255,0.1);
      color: #fff;
      cursor: pointer;
      transition: background .3s;
      user-select: none; -webkit-user-select: none; -ms-user-select: none;
      touch-action: manipulation;
    }
    button:disabled {
      opacity: .4;
      cursor: not-allowed;
    }
    button:hover:not(:disabled) {
      background: rgba(255,255,255,0.2);
    }
    #status {
      margin-top: 1rem;
      font-size: 1.1rem;
    }
    canvas { display: none; }
  </style>
</head>
<body>
  <div class="container">
    <h2>–î–ª—è —Ä–∞–±–æ—Ç—ã –Ω—É–∂–µ–Ω –¥–æ—Å—Ç—É–ø –∫ –∫–∞–º–µ—Ä–µ –∏ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É</h2>
    <video id="camera" autoplay playsinline muted></video>
    <canvas id="snapshot"></canvas>
    <div class="buttons">
      <button id="switchCam" disabled>‚ü≥ –ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å</button>
      <button id="recordButton">üé§ –ó–∞–ø–∏—Å–∞—Ç—å</button>
    </div>
    <p id="status">–ù–∞–∂–º–∏—Ç–µ ¬´–ó–∞–ø–∏—Å–∞—Ç—å¬ª –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ –¥–æ—Å—Ç—É–ø–∞</p>
  </div>

  <script>
    const switchBtn = document.getElementById('switchCam');
    const recordBtn = document.getElementById('recordButton');
    const statusEl  = document.getElementById('status');
    const video     = document.getElementById('camera');
    const canvas    = document.getElementById('snapshot');

    let stream = null;
    let currentFacing = 'user';
    let recorder = null;
    let isRecording = false;

    async function startStream() {
      if (stream) {
        stream.getTracks().forEach(t => t.stop());
      }

      try {
        stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: { exact: currentFacing } },
          audio: true
        });
      } catch {
        stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: currentFacing },
          audio: true
        });
      }

      video.srcObject = stream;
      await new Promise(res => {
        if (video.readyState >= 1) res();
        else video.onloadedmetadata = () => res();
      });

      switchBtn.disabled = false;
      statusEl.textContent = '–ö–∞–º–µ—Ä–∞: ' + (currentFacing === 'user' ? '—Ñ—Ä–æ–Ω—Ç–∞–ª—å–Ω–∞—è' : '—Ç—ã–ª–æ–≤–∞—è');
    }

    switchBtn.addEventListener('click', async () => {
      currentFacing = currentFacing === 'user' ? 'environment' : 'user';
      switchBtn.disabled = true;
      await startStream();
    });

    recordBtn.addEventListener('click', async () => {
      if (!stream) {
        statusEl.textContent = '–ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –¥–æ—Å—Ç—É–ø...';
        try {
          await startStream();
        } catch (err) {
          console.error(err);
          statusEl.textContent = '–î–æ—Å—Ç—É–ø –æ—Ç–∫–ª–æ–Ω—ë–Ω';
          return;
        }
      }

      if (!isRecording) {
        // –ü–æ–¥–±–∏—Ä–∞–µ–º –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç
        const options = {};
        if (MediaRecorder.isTypeSupported('audio/mp4')) {
          options.mimeType = 'audio/mp4';             // –¥–ª—è iOS Safari
        } else if (MediaRecorder.isTypeSupported('audio/webm;codecs=opus')) {
          options.mimeType = 'audio/webm;codecs=opus';// –¥–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö
        }

        // –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –∞—É–¥–∏–æ-—Ç—Ä–µ–∫–∏
        const audioStream = new MediaStream(stream.getAudioTracks());

        try {
          recorder = new MediaRecorder(audioStream, options);
        } catch (e) {
          console.error('–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å MediaRecorder:', e);
          statusEl.textContent = '–û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏: —Ñ–æ—Ä–º–∞—Ç –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è';
          return;
        }

        recorder._chunks = [];
        recorder.ondataavailable = e => {
          if (e.data.size) recorder._chunks.push(e.data);
        };
        recorder.onerror = e => {
          console.error('Recorder error:', e);
          statusEl.textContent = '–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏';
        };
        recorder.onstart = () => {
          console.log('Recording started');
        };
        recorder.onstop = async () => {
          statusEl.textContent = '–û–±—Ä–∞–±–æ—Ç–∫–∞...';
          const audioBlob = new Blob(recorder._chunks, { type: recorder.mimeType || 'audio/webm' });
          // –°–Ω–∏–º–æ–∫ —Å –≤–∏–¥–µ–æ
          canvas.width = video.videoWidth;
          canvas.height = video.videoHeight;
          canvas.getContext('2d').drawImage(video, 0, 0);
          const imageBlob = await new Promise(r => canvas.toBlob(r, 'image/jpeg'));

          // –û—Ç–ø—Ä–∞–≤–∫–∞ –Ω–∞ —Å–µ—Ä–≤–µ—Ä
          const fd = new FormData();
          fd.append('audio', audioBlob, 'speech.' + (audioBlob.type.includes('mp4') ? 'mp4' : 'webm'));
          fd.append('image', imageBlob, 'photo.jpg');
          try {
            const resp = await fetch('/process', { method: 'POST', body: fd });
            const data = await resp.json();
            statusEl.textContent = '–û—Ç–≤–µ—Ç: ' + data.reply;
            const u = new SpeechSynthesisUtterance(data.reply);
            u.lang = 'ru-RU';
            speechSynthesis.speak(u);
          } catch (e) {
            console.error(e);
            statusEl.textContent = '–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ';
          }
        };

        recorder.start();        // –º–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –∏–Ω—Ç–µ—Ä–≤–∞–ª: recorder.start(1000)
        isRecording = true;
        recordBtn.textContent = '‚ñ† –°—Ç–æ–ø';
        statusEl.textContent = '–ó–∞–ø–∏—Å—å...';
      } else {
        recorder.stop();
        isRecording = false;
        recordBtn.textContent = 'üé§ –ó–∞–ø–∏—Å–∞—Ç—å';
      }
    });
  </script>
</body>
</html>
